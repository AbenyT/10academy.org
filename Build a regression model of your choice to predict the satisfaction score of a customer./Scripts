import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Load the dataset
file_path = 'D:/10 Acadamy kifiya/Technical Content/data/Week1_challenge_data_source(CSV)'
data = pd.read_csv(file_path)

# Assume engagement_score and experience_score have been computed already as in previous steps
# and satisfaction_score has been computed as well.

# Features to use for predicting the satisfaction score
features = ['Avg RTT DL (ms)', 'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)', 
            'TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)', 'engagement_score', 'experience_score']

# Target variable
target = 'satisfaction_score'

# Drop rows with missing values in the selected columns
data = data.dropna(subset=features + [target])

# Split the data into training and testing sets (80% train, 20% test)
X = data[features]
y = data[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Choose a regression model (Linear Regression, Random Forest Regressor, etc.)
# You can change this to another regression model if needed

# Model 1: Linear Regression
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Model 2: Random Forest Regressor (Uncomment if you want to try this instead)
# rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
# rf_model.fit(X_train, y_train)

# Predictions on the test set
y_pred_lr = lr_model.predict(X_test)

# Uncomment below if using Random Forest model
# y_pred_rf = rf_model.predict(X_test)

# ---------------- Evaluate the Model ------------------
# For Linear Regression Model
mse_lr = mean_squared_error(y_test, y_pred_lr)
r2_lr = r2_score(y_test, y_pred_lr)

print("Linear Regression Model:")
print("Mean Squared Error:", mse_lr)
print("R² Score:", r2_lr)

# For Random Forest Model (Uncomment below if using RF model)
# mse_rf = mean_squared_error(y_test, y_pred_rf)
# r2_rf = r2_score(y_test, y_pred_rf)

# print("\nRandom Forest Regressor Model:")
# print("Mean Squared Error:", mse_rf)
# print("R² Score:", r2_rf)

# Plot actual vs predicted values for Linear Regression
plt.scatter(y_test, y_pred_lr, color='blue', label='Predictions')
plt.plot(y_test, y_test, color='red', label='Actual')
plt.title('Actual vs Predicted Satisfaction Scores (Linear Regression)')
plt.xlabel('Actual Satisfaction Score')
plt.ylabel('Predicted Satisfaction Score')
plt.legend()
plt.show()

# Save predictions to a CSV (optional)
output_path = 'D:/10 Acadamy kifiya/Technical Content/data/satisfaction_predictions.csv'
prediction_results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_lr})
prediction_results.to_csv(output_path, index=False)

